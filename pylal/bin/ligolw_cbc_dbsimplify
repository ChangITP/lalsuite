#!/usr/bin/env python

# ============================================================================
#
#                               Preamble
#
# ============================================================================


from optparse import OptionParser
import sqlite3
import sys
import os
import time

from glue.ligolw import lsctables
from glue.ligolw import dbtables
from glue.ligolw.utils import process
from glue import git_version

from pylal import ligolw_sqlutils as sqlutils

__prog__ = "ligolw_cbc_dbsimplify"
__author__ = "Collin Capano <cdcapano@physics.syr.edu>"

description = \
"Cleans and simplifies a database by removing redundant ids."

# ============================================================================
#
#                               Set Options
#
# ============================================================================

def parse_command_line():
    """
    Parser function dedicated
    """
    parser = OptionParser(
        version = git_version.verbose_msg,
        usage   = "%prog [options]",
        description = description
        )
    # following are related to file input and output naming
    parser.add_option( "-d", "--database", action = "store", type = "string", default = None,
        help =
            "Database to update. Must already exist."
            )
    parser.add_option( "-t", "--tmp-space", action = "store", type = "string", default = None,
        metavar = "PATH",
        help =
            "Location of local disk on which to do work. This is optional; " +
            "it is only used to enhance performance in a networked " +
            "environment. "
            )
    parser.add_option( "", "--vacuum", action = "store_true", default = False,
        help = 
            "If turned on, will vacuum the database before saving. " +
            "This cleans any fragmentation and removes empty space " +
            "left behind by all the DELETEs, making the output " +
            "database smaller and more efficient. " +
            "WARNING: Since this requires rebuilding the entire " +
            "database, this can take awhile for larger files." 
            )

    parser.add_option( "-v", "--verbose", action = "store_true", default = False,
        help =
            "Print progress information"
           )
    parser.add_option( "-D", "--debug", action = "store_true", default = False,
        help =
            "Print SQLite queries used and the approximate time taken to run each one." )

    (options, args) = parser.parse_args()
    # check for required options and for self-consistency
    if not options.database:
        raise ValueError, "No database specified."

    return options, sys.argv[1:]


# =============================================================================
#
#                                     Main
#
# =============================================================================

opts, args = parse_command_line()

# get input database filename
filename = opts.database
if not os.path.isfile( filename ):
    raise ValueError, "The input file, %s, cannot be found." % filename

# Setup working databases and connections
if opts.verbose: 
    print >> sys.stdout, "Creating a database connection..."
working_filename = dbtables.get_connection_filename( 
    filename, tmp_path = opts.tmp_space, verbose = opts.verbose )
connection = sqlite3.connect( working_filename )
if opts.tmp_space:
    dbtables.set_temp_store_directory(connection, opts.tmp_space, verbose = opts.verbose)
dbtables.DBTable_set_connection( connection )

# Add program to process and process params table

# FIXME: remove the following two lines once boolean type
# has been properly handled
from glue.ligolw import types as ligolwtypes
ligolwtypes.FromPyType[type(True)] = ligolwtypes.FromPyType[type(8)]

xmldoc = dbtables.get_xml(connection)
proc_id = process.register_to_xmldoc(xmldoc, 'ligolw_cbc_dbsimplify', opts.__dict__, version = git_version.id)

# create needed functions
connection.create_function("concat_2cols", 2, sqlutils.concatenate)
connection.create_function("concat_5cols", 5, sqlutils.concatenate)
connection.create_function("concat_7cols", 7, sqlutils.concatenate)

# create needed indices on tables if they don't already exist
current_indices = [index[0] for index in 
    connection.cursor().execute('SELECT name FROM sqlite_master WHERE type == "index"').fetchall()]
sqlscript = ''
if 'ts_io_index' not in current_indices:
    sqlscript += 'CREATE INDEX ts_io_index ON time_slide (instrument, offset);\n'
if 'e_sgitlc_index' not in current_indices:
    sqlscript += 'CREATE INDEX e_sgitlc_index ON experiment (search, search_group, instruments, gps_start_time, gps_end_time, lars_id, comments);\n'
if 'es_etvds_index' not in current_indices:
    sqlscript += 'CREATE INDEX es_etvds_index ON experiment_summary (experiment_id, time_slide_id, veto_def_name, datatype, sim_proc_id);\n'
if 'em_esi_index' not in current_indices:
    sqlscript += 'CREATE INDEX em_esi_index ON experiment_map (experiment_summ_id);\n'
if 'em_cei_index' not in current_indices:
    sqlscript += 'CREATE INDEX em_cei_index ON experiment_map (coinc_event_id);\n'

if sqlscript != '':
    if opts.verbose:
        print >> sys.stdout, "Creating needed indices..."
    connection.cursor().executescript(sqlscript)


if opts.verbose:
   print >> sys.stdout, "Cleaning up the segments tables..."

sqlscript = """
--
-- Cleaning up the segments tables as well as the associated
-- entries in the process & process_params tables
-- 

-- Create a table that combines the info from the segment_definer &
-- segment_summary tables. Then for each unique set of (ifo, cat_vers, times)
-- keep only the lowest process_id.
CREATE TEMP TABLE segments_tbl AS
    SELECT
        segment_definer.process_id AS proc_id,
        segment_definer.segment_def_id AS segdef_id,
        segment_definer.ifos AS ifo,
        concat_2cols(segment_definer.name, segment_definer.version) AS cat_vers,
        concat_2cols(segment_summary.start_time, segment_summary.end_time) AS times
    FROM
        segment_definer
        JOIN segment_summary ON (
            segment_definer.process_id == segment_summary.process_id
            AND segment_definer.segment_def_id == segment_summary.segment_def_id)
    GROUP BY proc_id;

DELETE FROM segments_tbl
    WHERE proc_id NOT IN (
        SELECT MIN(proc_id)
        FROM segments_tbl
        GROUP BY ifo, cat_vers, times);

-- Remove duplicate entries related to vetoes and segments in the process 
-- & process_params tables
DELETE FROM process
    WHERE
        process_id NOT IN (SELECT proc_id FROM segments_tbl)
        AND program == ".executables/ligolw_segments_from_cats";
DELETE FROM process_params
    WHERE
        process_id NOT IN (SELECT proc_id FROM segments_tbl)
        AND program == ".executables/ligolw_segments_from_cats";

-- Remove duplicate entries in the segment, segment_summary & 
-- segment_definer tables
DELETE FROM segment 
    WHERE process_id NOT IN (SELECT proc_id FROM segments_tbl);
DELETE FROM segment_definer 
    WHERE process_id NOT IN (SELECT proc_id FROM segments_tbl);
DELETE FROM segment_summary
    WHERE process_id NOT IN (SELECT proc_id FROM segments_tbl);

DROP TABLE segments_tbl;
"""
if opts.debug:
    print >> sys.stderr, sqlscript
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]
connection.cursor().executescript( sqlscript )
if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

if opts.verbose:
    print >> sys.stdout, "Cleaning up the veto_definer table..."

sqlscript = """
CREATE TEMP TABLE veto_procinfo AS
    SELECT
        process.process_id,
        concat_7cols(process.program, process.version, process.username,
            process.ifos, process.cvs_entry_time, process.cvs_repository, 
            process.comment) AS process_info
    FROM process
    WHERE
        process.process_id IN (
            SELECT veto_definer.process_id
            FROM veto_definer
            GROUP BY veto_definer.process_id);

CREATE TEMP TABLE _veto_pidmap_ AS
    SELECT
        old_procinfo.process_id AS old_pid,
        MIN(new_procinfo.process_id) AS new_pid
    FROM
        veto_procinfo AS old_procinfo
        JOIN veto_procinfo AS new_procinfo ON (
            new_procinfo.process_info == old_procinfo.process_info)
    GROUP BY old_pid;

DELETE FROM process
    WHERE process_id IN (
        SELECT old_pid
        FROM _veto_pidmap_
        WHERE old_pid != new_pid);
DELETE FROM veto_definer
    WHERE process_id IN (
        SELECT old_pid
        FROM _veto_pidmap_
        WHERE old_pid != new_pid);

DROP TABLE veto_procinfo;
DROP TABLE _veto_pidmap_;
"""
if opts.debug:
    print >> sys.stderr, sqlscript
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]
connection.cursor().executescript( sqlscript )
if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

if opts.verbose:
   print >> sys.stdout, "Collect useful information from process and process_params tables"

sqlscript = """
CREATE TEMP TABLE proc_params AS
    SELECT
        process.process_id AS proc_id,
        process.program AS program,
        group_concat(pp_table.value) AS value,
        group_concat(pp_table.param) AS params,
        concat_5cols(process.start_time, process.end_time, process.username,
            process.node, process.version) AS process_info
    FROM
        process_params AS pp_table
        JOIN process ON (
            pp_table.process_id == process.process_id)
    GROUP BY proc_id;

CREATE TEMP TABLE _pidmap_ AS
    SELECT
        old_pp_table.proc_id AS old_pid,
        MIN(new_pp_table.proc_id) AS new_pid,
        old_pp_table.program AS program
    FROM
        proc_params AS old_pp_table
        JOIN proc_params AS new_pp_table ON (
            old_pp_table.value == new_pp_table.value
            AND old_pp_table.process_info == new_pp_table.process_info
            AND old_pp_table.params == new_pp_table.params
            AND old_pp_table.program == new_pp_table.program)
    GROUP BY old_pid;

CREATE INDEX pidmap_index ON _pidmap_ (old_pid);

"""
if opts.debug:
    print >> sys.stderr, sqlscript
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]
connection.cursor().executescript( sqlscript )
if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

if opts.verbose:
    print >> sys.stdout, "Clean up the time_slide table ..."

sqlscript = """
--
-- Cleaning up the time_slide table
--

-- Update the process_ids in the time_slide table with the new ids from _pidmap_
UPDATE time_slide 
    SET process_id = (
        SELECT new_pid 
        FROM _pidmap_ 
        WHERE process_id == old_pid);

-- Create a table that combines the information about a single time_slide into 
-- a single row.  This makes comparison between time_slides easier.
CREATE TEMP TABLE compact_time_slide AS
    SELECT
        time_slide_id AS tsid,
        process_id AS pid,
        group_concat(instrument) AS ifos,
        group_concat(offset) AS offset
    FROM time_slide
    GROUP BY time_slide_id;

-- Create a table that maps the time_slide_ids of redundant time_slide entries
-- to those entries one is going to keep.
CREATE TEMP TABLE _tsidmap_ AS
    SELECT
        old_ts_table.tsid AS old_tsid,
        MIN(new_ts_table.tsid) AS new_tsid
    FROM
        compact_time_slide AS old_ts_table
        JOIN compact_time_slide AS new_ts_table ON (
            new_ts_table.pid == old_ts_table.pid
            AND new_ts_table.ifos == old_ts_table.ifos
            AND new_ts_table.offset == old_ts_table.offset)
    GROUP BY old_tsid;

DROP TABLE compact_time_slide;

CREATE INDEX tsidmap_index ON _tsidmap_ (old_tsid);

-- Update the coinc_event and experiment_summary tables with new time_slide_ids
UPDATE coinc_event 
    SET time_slide_id = (
        SELECT new_tsid 
        FROM _tsidmap_ 
        WHERE old_tsid == time_slide_id);
UPDATE experiment_summary
    SET time_slide_id = (
        SELECT new_tsid 
        FROM _tsidmap_ 
        WHERE old_tsid == time_slide_id);

DROP INDEX tsidmap_index;

-- Delete the redundant entries in the time_slide table
DELETE FROM time_slide 
    WHERE time_slide_id IN (
        SELECT old_tsid 
        FROM _tsidmap_ 
        WHERE old_tsid != new_tsid);

DROP TABLE _tsidmap_;

"""
if opts.debug:
    print >> sys.stderr, sqlscript
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]
connection.cursor().executescript( sqlscript )
if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

if opts.verbose:
    print >> sys.stdout, "Cleaning up the coinc_definer table..."

sqlscript = """
--
-- Cleaning up the coinc_definer table
--

-- Create a table that maps the coinc_definer_ids of redundant entries
-- to those entries one is going to keep.
CREATE TEMP TABLE _cdidmap_ AS
    SELECT
        old_cd_table.coinc_def_id AS old_cdid,
        MIN(new_cd_table.coinc_def_id) AS new_cdid
    FROM
        coinc_definer AS old_cd_table
        JOIN coinc_definer AS new_cd_table ON (
            new_cd_table.search == old_cd_table.search
            AND new_cd_table.search_coinc_type == old_cd_table.search_coinc_type
        )
    GROUP BY old_cdid;

CREATE INDEX cdidmap_index ON _cdidmap_ (old_cdid);

-- Update the coinc_event table with new coinc_def_ids
UPDATE coinc_event 
    SET coinc_def_id = (
        SELECT new_cdid 
        FROM _cdidmap_ 
        WHERE old_cdid == coinc_def_id);

DROP INDEX cdidmap_index;

-- Remove redundant entries in the coinc_definer table
DELETE FROM coinc_definer
     WHERE coinc_def_id IN (
     SELECT old_cdid 
     FROM _cdidmap_
     WHERE old_cdid != new_cdid);

DROP TABLE _cdidmap_;
"""
if opts.debug:
    print >> sys.stderr, sqlscript
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]
connection.cursor().executescript( sqlscript )
if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]


if opts.verbose:
    print >> sys.stdout, "Checking whether this database has simulation tables..."

programs = connection.cursor().execute('SELECT program FROM process GROUP BY program').fetchall()
for idx, entry in enumerate(programs):
    programs[idx] = entry[0]

if len(set(['inspinj','rinj']) & set(programs)) != 0:
    if opts.verbose:
        print >> sys.stdout, "Cleaning simulation tables..."
    
    sqlscript = """
    --
    -- Simulation Tables Clean-up
    --

    -- Update sim_proc_ids in the experiment_summary table
    UPDATE experiment_summary 
        SET sim_proc_id = (
            SELECT new_pid 
            FROM _pidmap_ 
            WHERE old_pid == sim_proc_id);

    """
    if 'inspinj' in programs:
        sqlscript += """
        -- Delete duplicate entries in the simulation tables
        DELETE FROM sim_inspiral 
            WHERE process_id IN (
                SELECT old_pid 
                FROM _pidmap_ 
                WHERE 
                    old_pid != new_pid
                    AND program == "inspinj");
        """
    if 'rinj' in programs:
        sqlscript += """
        DELETE FROM sim_ringdown 
            WHERE process_id IN (
                SELECT old_pid 
                FROM _pidmap_ 
                WHERE 
                    old_pid != new_pid
                    AND program == "rinj");
        """
    if opts.debug:
        print >> sys.stderr, sqlscript
        print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]
    connection.cursor().executescript( sqlscript )
    if opts.debug:
        print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]


if opts.verbose:
    print >> sys.stdout, "Cleaning experiment tables..."

sqlscript = """
--
-- Experiment Tables clean up
--

-- experiment table clean up:
-- create map table to map experiment_ids that are to be kept
-- to experiment ids that are to be discarded, in the same manner
-- as done above

CREATE TEMP TABLE expr_info AS
    SELECT
        expr.experiment_id AS eid,
        concat_7cols(expr.search, expr.search_group, expr.instruments,
            expr.gps_start_time, expr.gps_end_time, expr.lars_id, expr.comments) AS info
    FROM experiment AS expr;

CREATE TEMP TABLE _eidmap_ AS
    SELECT
        old_exp.eid AS old_eid,
        MIN(new_exp.eid) AS new_eid
    FROM
        expr_info AS old_exp
        JOIN expr_info AS new_exp ON (
            old_exp.info == new_exp.info)
    GROUP BY old_eid;

DROP INDEX e_sgitlc_index;

-- delete the old ids from the experiment table
DELETE FROM experiment 
    WHERE experiment_id IN (
        SELECT old_eid 
        FROM _eidmap_
        WHERE old_eid != new_eid);

-- update the experiment_ids in the experiment summary table
CREATE INDEX em_old_index ON _eidmap_ (old_eid);
UPDATE experiment_summary
    SET experiment_id = (
        SELECT new_eid 
        FROM _eidmap_
        WHERE experiment_summary.experiment_id == old_eid);

DROP INDEX em_old_index;

-- experiment summary clean up

-- create a table to map esids to be deleted to esids to be saved
CREATE TEMP TABLE expr_summ_info AS
    SELECT
        expr_summ.experiment_summ_id AS esid,
        concat_5cols(expr_summ.experiment_id, expr_summ.time_slide_id, 
            expr_summ.veto_def_name, expr_summ.datatype, expr_summ.sim_proc_id) AS info
    FROM experiment_summary AS expr_summ;

CREATE TEMP TABLE _esidmap_ AS
    SELECT
        old_expsumm.esid AS old_esid,
        MIN(new_expsumm.esid) AS new_esid
    FROM
        expr_summ_info AS old_expsumm
        JOIN expr_summ_info AS new_expsumm ON (
            old_expsumm.info == new_expsumm.info)
    GROUP BY old_esid;

DROP INDEX es_etvds_index;
CREATE INDEX esidmap_index on _esidmap_ (old_esid, new_esid);

-- sum durations and nevents
CREATE TEMP TABLE sum_dur_nevents AS
    SELECT
        _esidmap_.new_esid AS esid, 
        SUM(experiment_summary.duration) AS sum_dur, 
        SUM(experiment_summary.nevents) AS sum_nevents
    FROM _esidmap_
        JOIN experiment_summary ON (
            _esidmap_.old_esid == experiment_summary.experiment_summ_id)
    GROUP BY esid;

CREATE INDEX sdn_esid_index ON sum_dur_nevents (esid);

-- delete the old ids from the experiment_summary table
DELETE FROM experiment_summary
    WHERE experiment_summ_id IN (
        SELECT old_esid
        FROM _esidmap_
        WHERE old_esid != new_esid);

-- update the durations and the nevents
UPDATE experiment_summary
    SET duration = (
        SELECT sum_dur
        FROM sum_dur_nevents
        WHERE sum_dur_nevents.esid == experiment_summary.experiment_summ_id),
    nevents = (
        SELECT sum_nevents
        FROM sum_dur_nevents
        WHERE sum_dur_nevents.esid == experiment_summary.experiment_summ_id);

DROP INDEX sdn_esid_index;

-- update the experiment_map table
UPDATE experiment_map
    SET experiment_summ_id = (
        SELECT new_esid 
        FROM _esidmap_
        WHERE experiment_map.experiment_summ_id == old_esid);

DROP INDEX esidmap_index;
DROP TABLE _esidmap_;
"""
if opts.debug:
    print >> sys.stderr, sqlscript
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]
connection.cursor().executescript( sqlscript )
if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]


if opts.verbose:
    print >> sys.stdout, "Deleting redundant rows in the process & process_params tables"

sqlscript = """
-- Remove redundant process rows
DELETE FROM process 
    WHERE process_id IN (
        SELECT old_pid 
        FROM _pidmap_ 
        WHERE old_pid != new_pid
            AND (program = "inspinj"
                OR program = "rinj"
                OR program = "ligolw_tisi") );
DELETE FROM process_params 
        WHERE process_id IN (
        SELECT old_pid 
        FROM _pidmap_ 
        WHERE old_pid != new_pid
            AND (program = "inspinj"
                OR program = "rinj"
                OR program = "ligolw_tisi") );

DROP INDEX pidmap_index;
DROP TABLE _pidmap_;
"""
if opts.debug:
    print >> sys.stderr, sqlscript
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]
connection.cursor().executescript( sqlscript )
if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

# Vacuum database if desired
if opts.vacuum:
    if opts.verbose:
        print >> sys.stderr, "Vacuuming database..."
    connection.cursor().execute( 'VACUUM' )

#
#       Save and Exit
#

connection.commit()
connection.close()

# write output database
dbtables.put_connection_filename(filename, working_filename, verbose = opts.verbose)

if opts.verbose: 
    print >> sys.stdout, "Finished!"

# set process end time
process.set_process_end_time(proc_id)
sys.exit(0)

